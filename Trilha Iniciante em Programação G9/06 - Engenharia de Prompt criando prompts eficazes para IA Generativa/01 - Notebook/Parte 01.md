# **CURSO 06 - Engenharia de Prompt: criando prompts eficazes para IA Generativa**

### IntroduÃ§Ã£o ao Curso de Engenharia de Prompt

### Lembretes

- Engenharia de Prompt
- Modelo de Linguagem (LLM)
- TÃ©cnicas e PrincÃ­pios
- Artigos CientÃ­ficos
- API

### AnotaÃ§Ãµes

**ApresentaÃ§Ã£o:**

- Instrutor: FabrÃ­cio Carraro (Alura).
- Objetivo: Acompanhar o aluno na jornada de aprendizado.

**Estrutura do Curso (MÃ³dulos/Etapas):**

1. **Fundamentos dos Modelos de Linguagem:**
    - O que sÃ£o Modelos de Linguagem (LLMs - Large Language Models).
    - Funcionamento em segundo plano.
    - Conceitos mais relevantes sobre o tema.
2. **PrincÃ­pios da Engenharia de Prompt:**
    - DefiniÃ§Ã£o de Engenharia de Prompt.
    - TÃ©cnicas e princÃ­pios essenciais.
    - Objetivo: Criar prompts ideais para obter respostas desejadas dos LLMs.
3. **TÃ©cnicas Baseadas em Artigos CientÃ­ficos:**
    - ExploraÃ§Ã£o de tÃ©cnicas consolidadas.
    - Base em pesquisas de empresas lÃ­deres (OpenAI, Google, Anthropic, Mistral AI, etc.).
    - Abordagem teÃ³rica e prÃ¡tica.
4. **TÃ©cnicas ProgramÃ¡ticas (API e CÃ³digo):**
    - Foco no uso prÃ¡tico e tÃ©cnico via programaÃ§Ã£o.
    - Voltado para integraÃ§Ã£o com APIs.
    - Ãštil para nÃ£o-programadores entenderem o funcionamento interno.

**ConclusÃ£o do Instrutor:**

- Mensagem de boas-vindas e desejo de uma boa jornada de aprendizado.

<aside>
ğŸ“Œ **RESUMO**:

Este mÃ³dulo introdutÃ³rio, apresentado por FabrÃ­cio Carraro da Alura, delineia a estrutura do curso de Engenharia de Prompt. O conteÃºdo serÃ¡ dividido em quatro partes principais: primeiro, os fundamentos dosÂ **Modelos de Linguagem (LLMs)**; segundo, osÂ **princÃ­pios da Engenharia de Prompt**Â para criar instruÃ§Ãµes eficazes; terceiro, o estudo deÂ **tÃ©cnicas baseadas em artigos cientÃ­ficos**Â de empresas especializadas; e por fim, uma visÃ£o sobre tÃ©cnicasÂ **programÃ¡ticas usando API e cÃ³digo**, Ãºteis mesmo para quem nÃ£o Ã© da Ã¡rea de computaÃ§Ã£o. O curso promete uma jornada do conceito fundamental Ã  aplicaÃ§Ã£o prÃ¡tica e tÃ©cnica.

</aside>

---

### Fundamentos dos Modelos de Linguagem (LLMs)

### Lembretes

- Modelo de Linguagem (LLM)
- Word Embeddings
- RepresentaÃ§Ã£o NumÃ©rica
- PrevisÃ£o de Palavras
- Contexto

### AnotaÃ§Ãµes

**DefiniÃ§Ã£o e Objetivo:**

- Modelos de Linguagem aprendemÂ **padrÃµes**Â eÂ **relaÃ§Ãµes**Â entre palavras de um idioma.
- Exemplo: Em portuguÃªs, apÃ³s o verbo "gostar" vem a preposiÃ§Ã£o "de". Em inglÃªs ("like") e turco ("pizza severim"), a estrutura Ã© diferente.
- O modelo Ã© treinado com grandes volumes de dados para internalizar essas regras.

**Como Funcionam (Teoria): Word Embeddings**

- Palavras sÃ£o convertidas emÂ **vetores numÃ©ricos**Â (nÃºmeros) chamadosÂ **embeddings**.
- Esses vetores capturam oÂ **significado**Â e aÂ **proximidade semÃ¢ntica**Â entre palavras.
    - Ex: "Carro" estÃ¡ prÃ³ximo de "Ã´nibus" e "tÃ¡xi" (transporte) e distante de "cachorro" ou "escola".
- PermitemÂ **operaÃ§Ãµes matemÃ¡ticas**:
    - Ex: Rei - Homem + Mulher = Rainha (relaÃ§Ã£o de gÃªnero).
    - Ex: Andando + [operaÃ§Ã£o] = Andei (relaÃ§Ã£o de tempo verbal).

**Funcionamento PrÃ¡tico: PrevisÃ£o**

- A funÃ§Ã£o principal de um LLM Ã©Â **prever a prÃ³xima palavra**Â mais provÃ¡vel em uma sequÃªncia.
- Ã‰ umÂ **autocomplete sofisticado**, que calcula probabilidades para cada palavra possÃ­vel.
    - Ex: ApÃ³s "...quero trabalhar", as prÃ³ximas palavras mais provÃ¡veis sÃ£o "com" (45%), "nessa" (25%), etc.

**CaracterÃ­stica Crucial: Contexto**

- LLMs mantÃªm oÂ **contexto**Â da conversa.
- Eles se lembram de perguntas e respostas anteriores dentro de uma mesma sessÃ£o (chat).
    - Ex: ApÃ³s perguntar sobre RogÃ©rio Ceni, o modelo entende que "dele" na pergunta seguinte se refere a ele, sem necessidade de repetir o nome.

<aside>
ğŸ“Œ **RESUMO**:

Um Modelo de Linguagem (LLM) Ã© um sistema treinado para entender os padrÃµes de um idioma. Internamente, ele representa palavras comoÂ **vetores numÃ©ricos (embeddings)**Â que capturam relaÃ§Ãµes de significado e permitem atÃ© operaÃ§Ãµes matemÃ¡ticas (ex: conceito de gÃªnero). Sua funÃ§Ã£o prÃ¡tica Ã© atuar como umÂ **preditorde prÃ³xima palavra**, calculando probabilidades com base no contexto fornecido. A capacidade deÂ **manter o contexto**Â de uma conversa Ã© o que torna ferramentas como o ChatGPT tÃ£o poderosas, permitindo diÃ¡logos coerentes e longos.

</aside>

---

### Temperatura e Tokens em Modelos de Linguagem

### Lembretes

- Temperatura (Temperature)
- Probabilidade
- Token
- TokenizaÃ§Ã£o
- PrevisÃ£o EstocÃ¡stica

### AnotaÃ§Ãµes

**1. O Conceito de Temperatura:**

- **O que Ã©:**Â Um parÃ¢metro que controla aÂ **aleatoriedade**Â (estocasticidade) das previsÃµes do modelo.
- **Funcionamento:**
    - **Temperatura Baixa (ex: 0):**Â O modelo quase sempre escolhe a palavra comÂ **maior probabilidade**. As respostas sÃ£o consistentes, previsÃ­veis e podem soar robÃ³ticas.
        - Ex: "Eu gosto muito de comer [chocolate]" repetidamente.
    - **Temperatura Alta (ex: 1.4):**Â O modelo tem maior chance de escolher palavrasÂ **menos provÃ¡veis**. As respostas sÃ£o maisÂ **criativas**, diversificadas e imprevisÃ­veis, mas podem incluir erros ou nonsenses se for muito alta (ex: >1.5).
        - Ex: "Eu gosto muito de comer pizza! Ã‰ uma delÃ­cia, nÃ£o acha?"
- **Objetivo:**Â Tornar as respostas mais naturais e humanas, imitando a variaÃ§Ã£o presente na linguagem humana.

**2. O Conceito de Tokens:**

- **O que Ã©:**Â AÂ **unidade bÃ¡sica**Â de processamento de um modelo de linguagem.Â **NÃ£o sÃ£o exatamente palavras.**
- **ComposiÃ§Ã£o:**Â Um token pode representar:
    - Uma palavra completa (ex: "curso").
    - Uma subpalavra ou pedaÃ§o de uma palavra (ex: "in" + "feliz" para "infeliz").
    - Um caractere especial ou pontuaÃ§Ã£o.
- **VariaÃ§Ã£o por Idioma:**Â O nÃºmero de tokens para um texto varia conforme o idioma e sua representatividade nos dados de treinamento do modelo.
    - **InglÃªs**Â (alto uso): Menos tokens por palavra (ex: 28 tokens para uma frase).
    - **PortuguÃªs**Â (uso mÃ©dio): Quantidade intermediÃ¡ria (ex: 37 tokens para a mesma frase).
    - **Grego**Â (baixo uso): Muitos tokens, often um por caractere (ex: 113 tokens para a mesma frase), por ser menos representado no treinamento.

<aside>
ğŸ“Œ **RESUMO**:

 AÂ **Temperatura**Â Ã© um parÃ¢metro que regula a criatividade do modelo: valores baixos geram respostas conservadoras e previsÃ­veis, enquanto valores altos permitem mais variedade e originalidade, com o risco de incoerÃªncia em extremos. JÃ¡ osÂ **Tokens**Â sÃ£o as unidades com as quais o modelo realmente trabalha, podendo ser palavras inteiras ou partes delas. A eficiÃªncia da tokenizaÃ§Ã£o depende do idioma, sendo mais eficaz em lÃ­nguas bem representadas nos dados de treinamento (como o inglÃªs) do que em outras (como o grego). Compreender esses conceitos Ã© crucial para efetivamente guiar e controlar as saÃ­das de um modelo de linguagem.

</aside>

---

### O que Ã© um Prompt e sua ImportÃ¢ncia na IA

### Lembretes

- Prompt
- Interface de Texto
- Linguagem Natural
- InteraÃ§Ã£o Humano-MÃ¡quina
- Engenharia de Prompt

### AnotaÃ§Ãµes

**Origem e DefiniÃ§Ã£o do Termo:**

- O termo "prompt" Ã© antigo na Ã¡rea de tecnologia.
- **Significado literal:**Â Verbo em inglÃªs que significa "incitar", "induzir" ou "motivar" uma aÃ§Ã£o.
- **Funcionamento:**Â A interface (prompt)Â *provoca*Â o usuÃ¡rio a fazer um pedido, que, ao ser enviado (comando), inicia a interaÃ§Ã£o.

**Prompt no Contexto da IA:**

- Ã‰ aÂ **entrada de texto**Â (instruÃ§Ã£o, pergunta, comando) fornecida a um modelo de linguagem (ex: ChatGPT).
- Permite que a interaÃ§Ã£o seja feita emÂ **linguagem natural**, assemelhando-se a uma conversa.
- Ã‰ oÂ **elemento fundamental**Â que "induz" o modelo a gerar uma resposta.

**A Necessidade de um Bom Prompt:**

- Criar um bom prompt requerÂ **tÃ©cnicas especÃ­ficas**Â (Engenharia de Prompt).
- A analogia: Assim como um palestrante adapta seu discurso aoÂ **pÃºblico-alvo**Â para ser eficaz, precisamos adaptar nossa comunicaÃ§Ã£o (o prompt) aoÂ **"pÃºblico"**Â (o modelo de linguagem).
- Para obter bons resultados, Ã© crucialÂ **entender os fundamentos**Â de como o modelo funciona.

<aside>
ğŸ“Œ **RESUMO**:

UmÂ **prompt**Â  Ã© a instruÃ§Ã£o em linguagem natural que damos a um modelo para gerar uma resposta. AÂ **Engenharia de Prompt**Â Ã© a prÃ¡tica de criar instruÃ§Ãµes eficazes, e sua importÃ¢ncia Ã© anÃ¡loga Ã  de adaptar uma mensagem ao seu pÃºblico: para se comunicar bem com o modelo e obter os melhores resultados, Ã© essencial entender como ele funciona.

</aside>

---

### PrincÃ­pios para a CriaÃ§Ã£o de um Prompt Ideal

### Lembretes

- Clareza nas InstruÃ§Ãµes
- DivisÃ£o de Tarefas
- Pensamento em Etapas
- Especificidade
- Contexto

### AnotaÃ§Ãµes

**PrincÃ­pio 1: Clareza e Especificidade**

- **Analogia:**Â Trate o modelo como um estagiÃ¡rio inteligente, mas que precisa de orientaÃ§Ã£o precisa.
- **Problema:**Â InstruÃ§Ãµes vagas geram resultados genÃ©ricos e pouco Ãºteis.
- **SoluÃ§Ã£o:**Â Seja extremamente claro e especÃ­fico. Defina:
    - **Formato**Â da resposta (ex: post para Instagram).
    - **PÃºblico-alvo**Â (ex: jovens).
    - **Tom e estilo**Â (ex: linguagem informal com gÃ­rias).
    - **Objetivo**Â final.

**PrincÃ­pio 2: Dividir Tarefas Complexas**

- **Problema:**Â QuestÃµes complexas (como problemas de lÃ³gica) frequentemente confundem o modelo, levando a respostas erradas ou "desconhecido".
- **SoluÃ§Ã£o:**Â Quebre o problema grande emÂ **sub-tarefas**Â menores e peÃ§a para o modelo executar uma de cada vez.
- **Exemplo PrÃ¡tico (Jogo de Detetive):**
    - **Prompt Ruim:**Â A pergunta direta resultou em uma resposta inconsistente e incorreta.
    - **Prompt Eficaz:**Â Instruir o modelo a: 1) Analisar cada dica individualmente, 2) Combinar as dicas relevantes, e 3)Â *SÃ³ entÃ£o*Â mapear a resposta final, garantiu um resultado correto e bem explicado.

**TÃ©cnicas Adicionais:**

- Solicitar que o modeloÂ **explique seus passos**Â ("pensamento em etapas").
- PedirÂ **justificativas**Â para a resposta.
- GerarÂ **mÃºltiplas respostas**Â e escolher a melhor ou mais consistente.

<aside>
ğŸ“Œ **RESUMO**:

Para criar prompts eficazes para modelos de linguagem, dois princÃ­pios sÃ£o fundamentais. Primeiro, aÂ **clareza e especificidade**: devemos dar instruÃ§Ãµes detalhadas como farÃ­amos com um estagiÃ¡rio, definindo contexto, formato e tom para evitar respostas vagas. Segundo,Â **dividir tarefas complexas**: problemas difÃ­ceis devem ser quebrados em etapas menores e sequenciais (analisar, combinar, concluir), guiando o raciocÃ­nio do modelo e aumentando drasticamente a precisÃ£o da resposta. Esses princÃ­pios formam a base para as tÃ©cnicas avanÃ§adas de engenharia de prompt.

</aside>

---

### TÃ©cnicas de Prompting: Zero-Shot e Few-Shot

### Lembretes

- Zero-Shot Prompting
- Few-Shot Prompting
- Exemplo
- PrecisÃ£o
- Alinhamento do Modelo

### AnotaÃ§Ãµes

**1. Zero-Shot Prompting:**

- **O que Ã©:**Â Enviar um promptÂ **sem fornecer nenhum exemplo**Â anterior.
- **Como funciona:**Â O modelo confia apenas em seu conhecimento interno prÃ©-treinado para gerar a resposta.
- **Vantagem:**Â Simples e direto. Funciona bem para tarefas comuns onde o modelo jÃ¡ Ã© proficiente.
- **Exemplo:**
    - Prompt:Â **`"Quem criou o ChatGPT?"`**
    - Resposta Esperada:Â **`"Foi criado pela OpenAI."`**

**2. Few-Shot Prompting:**

- **O que Ã©:**Â Enviar um prompt que incluiÂ **alguns exemplos**Â (shots) antes da pergunta real.
- **Objetivo:**Â "**Alinhar**" o modelo, fornecendo um contexto claro do formato e do tipo de raciocÃ­nio desejado na resposta. Ã‰ como dar uma "dica" ou um "modelo" a ser seguido.
- **Quando usar:**Â Ã‰ especialmente Ãºtil para:
    - Tarefas complexas ou incomuns.
    - Garantir um formato especÃ­fico de resposta.
    - Aumentar a confiabilidade e precisÃ£o em modelos menos capazes.
- **Estrutura do Prompt:**
    - **`Pergunta: [Exemplo 1]`**
    - **`Resposta: [Resposta do Exemplo 1]`**
    - **`Pergunta: [Exemplo 2]`**
    - **`Resposta: [Resposta do Exemplo 2]`**
    - **`Pergunta: [Sua pergunta real]`**
    - **`Resposta:`**

<aside>
ğŸ“Œ **RESUMO**:

Duas tÃ©cnicas fundamentais para melhorar as respostas de um modelo de linguagem sÃ£o oÂ **Zero-Shot**Â e oÂ **Few-Shot Prompting**. OÂ **Zero-Shot**Â Ã© fazer uma pergunta diretamente, sem exemplos, e Ã© eficaz para consultas simples. JÃ¡ oÂ **Few-Shot**Â envolve fornecer um ou mais exemplos antes da pergunta real, servindo como um guia para que o modelo entenda o formato, o estilo e o tipo de raciocÃ­nio esperado na resposta. Esta Ãºltima tÃ©cnica Ã© poderosa para aumentar a precisÃ£o em tarefas complexas, "alinhando" o modelo com a lÃ³gica que se deseja que ele siga. A escolha entre uma e outra depende da complexidade da tarefa e da confiabilidade do modelo que se estÃ¡ usando.

</aside>

---

### AplicaÃ§Ãµes PrÃ¡ticas do Few-Shot Prompting

### Lembretes

- Few-Shot Prompting
- GeneralizaÃ§Ã£o
- AnÃ¡lise de Sentimentos
- TraduÃ§Ã£o
- PadrÃ£o de Resposta

### AnotaÃ§Ãµes

**Conceito Revisado: Few-Shot Prompting**

- **DefiniÃ§Ã£o:**Â TÃ©cnica que forneceÂ **poucos exemplos**Â (shots) no prompt para "ensinar" o modelo a realizar uma tarefa especÃ­fica.
- **Objetivo:**Â Guiar o modelo a entender oÂ **formato**, oÂ **estilo**Â e oÂ **tipo de raciocÃ­nio**Â desejado na resposta, alinhando-o com a intenÃ§Ã£o do usuÃ¡rio.

**AplicaÃ§Ãµes em Diferentes Ãreas:**

**1. MatemÃ¡tica e LÃ³gica:**

- **Exemplo:**
    - **`Pergunta: O RogÃ©rio tem 5 bolas... Resposta: Ele tem 11 bolas.`**
    - **`Pergunta: Havia 23 maÃ§Ã£s... Resposta:`**
- **FunÃ§Ã£o:**Â Os exemplos direcionam o modelo aÂ **quebrar o problema em etapas**Â e realizar os cÃ¡lculos sequencialmente, melhorando a precisÃ£o.

**2. AnÃ¡lise de Sentimentos:**

- **Exemplo:**
    - **`"Esse filme foi terrÃ­vel" - Negativo.`**
    - **`"Esse Ã© o meu filme favorito" - Positivo.`**
- **FunÃ§Ã£o:**Â Os exemplos definem asÂ **categorias**Â (Positivo/Negativo) e ensinam o modelo aÂ **interpretar a nuance**Â da linguagem para classificar novos textos automaticamente.

**3. TraduÃ§Ã£o de Idiomas:**

- **Exemplo:**
    - **`InglÃªs: Hello... FrancÃªs: Bonjour...`**
    - **`InglÃªs: I am learning... FrancÃªs: J'apprends...`**
- **FunÃ§Ã£o:**Â Os exemplos estabelecem oÂ **par de idiomas**Â e oÂ **formato**Â da traduÃ§Ã£o (**`InglÃªs: [texto] FrancÃªs: [traduÃ§Ã£o]`**), permitindo que o modelo generalize e traduza novas frases seguindo o mesmo padrÃ£o.

**CaracterÃ­sticas Observadas:**

- **ConsistÃªncia:**Â O modelo tende a seguirÂ **rigorosamente o padrÃ£o**Â demonstrado nos exemplos (ex: usar ou nÃ£o pontuaÃ§Ã£o, manter a mesma estrutura).
- **GeneralizaÃ§Ã£o:**Â Com poucos exemplos, o modelo Ã© capaz de aplicar a lÃ³gica aprendida paraÂ **novas instÃ¢ncias**Â da mesma tarefa.
- **Flexibilidade:**Â A tÃ©cnica Ã©Â **adaptÃ¡vel**Â a diversas Ã¡reas do conhecimento, desde matemÃ¡tica atÃ© processamento de linguagem natural.

<aside>
ğŸ“Œ **RESUMO**:

OÂ **Few-Shot Prompting**Â Ã© uma tÃ©cnica versÃ¡til e poderosa para orientar modelos de linguagem. Fornecendo alguns exemplos especÃ­ficos, Ã© possÃ­vel "ensinar" o modelo a executar tarefas complexas e variadas, como resolver problemas matemÃ¡ticos, analisar sentimentos ou traduzir idiomas. Os exemplos servem como umÂ **modelo em miniatura**, definindo o padrÃ£o de raciocÃ­nio e formataÃ§Ã£o que o modelo deve replicar em suas respostas. Essa tÃ©cnica Ã© fundamental para extrair o mÃ¡ximo potencial de um LLM, garantindo respostas precisas e alinhadas com o objetivo desejado, mesmo em contextos diferentes.

</aside>

---

### Chain of Thought (CoT): Aprimorando o Few-Shot Prompting

### Lembretes

- Chain of Thought (CoT)
- Few-Shot Prompting
- RaciocÃ­nio Passo a Passo
- ResoluÃ§Ã£o de Problemas
- PrecisÃ£o

### AnotaÃ§Ãµes

**O Problema com o Few-Shot BÃ¡sico:**

- Fornecer apenas a resposta final **nÃ£o ensina o processo**Â de raciocÃ­nio ao modelo.
- Isso pode levar a erros em problemas complexos, onde o modelo "chuta" a resposta sem entender a lÃ³gica.

**A SoluÃ§Ã£o: Chain of Thought (CoT) Prompting:**

- **O que Ã©:**Â Uma tÃ©cnica de few-shot prompting onde os exemplosÂ **incluem o raciocÃ­nio passo a passo**Â que leva Ã  resposta final.
- **Objetivo:**Â "Ensinar" o modelo aÂ **simular um processo de pensamento**, quebrando um problema complexo em subetapas mais simples antes de dar a resposta.
- **Como funciona:**Â No prompt, cada exemplo mostra nÃ£o sÃ³ a pergunta e a resposta, masÂ **tambÃ©m a explicaÃ§Ã£o lÃ³gica**Â ("o porquÃª") que conecta uma Ã  outra.

**Exemplo PrÃ¡tico (ComparaÃ§Ã£o):**

- **Few-Shot BÃ¡sico (Menos Eficaz):**
    - **`P: O RogÃ©rio tem 5 bolas... R: Ele tem 11 bolas.`**
- **Few-Shot com Chain of Thought (Mais Eficaz):**
    - **`P: O RogÃ©rio tem 5 bolas... R: Ele inicialmente tinha 5. Comprou 2 caixas de 3 bolas (2*3=6). Portanto, agora tem 5 + 6 = 11 bolas.`**

**Resultado e Origem:**

- **Resultado:**Â Modelos que recebem exemplos com CoTÂ **reproduzem o mesmo raciocÃ­nio**Â para novas perguntas, resultando em uma precisÃ£o muito maior.
- **Origem:**Â TÃ©cnica formalizada em um artigo doÂ **Google Research/DeepMind**. Eles demonstraram que o CoT eleva significativamente o desempenho de LLMs em tarefas que requerem raciocÃ­nio lÃ³gico, matemÃ¡tico ou comum.

<aside>
ğŸ“Œ **RESUMO**:

- OÂ **Chain of Thought**Â nÃ£o Ã© uma tÃ©cnica nova, mas umÂ **aprimoramento poderoso**Â do Few-Shot Prompting.
- Ele Ã© extremamente eficaz porque forÃ§a o modelo aÂ **dedicar capacidade de processamento**Â para entender a jornada lÃ³gica (o "pensar"), e nÃ£o apenas o destino final (a resposta).
- Essa tÃ©cnica combina dois princÃ­pios fundamentais:Â **dividir tarefas complexas**Â eÂ **fornecer clareza**Â atravÃ©s de exemplos.
</aside>

---

### AplicaÃ§Ã£o PrÃ¡tica: Few-Shot + Chain of Thought para um Problema Complexo

### Lembretes

- Few-Shot Prompting
- Chain of Thought (CoT)
- PadrÃ£o de Resposta
- AutomatizaÃ§Ã£o
- AplicaÃ§Ã£o PrÃ¡tica

### AnotaÃ§Ãµes

**Objetivo do Exemplo:**

- Demonstrar o poder combinado doÂ **Few-Shot Prompting**Â com oÂ **Chain of Thought**Â para guiar um modelo na resoluÃ§Ã£o de um problema complexo e com regras especÃ­ficas (cÃ¡lculo de imposto).

**Estrutura do Prompt (O "Como"):**

1. **DefiniÃ§Ã£o Clara da Tarefa:**Â Explicitar precisamente o que deve ser feito (somar valores >40k, calcular 30%).
2. **Fornecimento de um Exemplo Simples (Few-Shot):**
    - Inclui umaÂ **pergunta-teste**Â com uma lista pequena de valores.
    - Fornece umaÂ **resposta modelo**Â que detalhaÂ **cada etapa**Â do raciocÃ­nio (Chain of Thought):
        - Contagem de valores elegÃ­veis.
        - Listagem dos valores.
        - CÃ¡lculo da soma.
        - CÃ¡lculo da porcentagem.
3. **ApresentaÃ§Ã£o do Problema Real:**Â A mesma pergunta Ã© repetida, mas com aÂ **lista completa de dados reais**.

**Resultado e EficÃ¡cia:**

- O modeloÂ **reproduziu perfeitamente**Â o padrÃ£o estabelecido no exemplo.
- Ele seguiuÂ **exatamente a mesma estrutura lÃ³gica**: contou (5 valores), listou (R$52k, R$103k...), somou (R$435k) e calculou a porcentagem (30% de R$435k = R$130.500).
- A resposta final foiÂ **correta e formatada**Â de forma idÃªntica Ã  do exemplo fornecido.

**ConclusÃµes e LiÃ§Ãµes Aprendidas:**

1. **Poder da CombinaÃ§Ã£o:**Â Few-Shot + CoT Ã© extremamente eficaz paraÂ **ensinar tarefas complexas**Â com regras especÃ­ficas.
2. **Reprodutibilidade:**Â O modelo Ã© capaz de aprender eÂ **replicar um padrÃ£o**Â de resposta de forma consistente.
3. **Aplicabilidade:**Â Esta tÃ©cnica Ã© Ãºtil paraÂ **automatizar**Â a geraÃ§Ã£o de relatÃ³rios, anÃ¡lises de dados e qualquer tarefa que siga uma estrutura repetitiva.
4. **LimitaÃ§Ã£o Consciente:**Â LLMsÂ **nÃ£o sÃ£o ferramentas de cÃ¡lculo ideais**. O exemplo serviu para ilustrar a tÃ©cnica, mas para matemÃ¡tica pesada, planilhas (Excel/Sheets) ou cÃ³digo sÃ£o mais adequados e confiÃ¡veis. A tÃ©cnica Ã© mais valiosa paraÂ **texto, formataÃ§Ã£o e lÃ³gica de negÃ³cio**.

<aside>
ğŸ“Œ **RESUMO**:

**O Few-Shot Prompting**Â (fornecer exemplos) comÂ **Chain of Thought**Â (exigir um raciocÃ­nio passo a passo) pode ser usada para "treinar" um modelo a resolver um problema complexo de forma estruturada e reproduzÃ­vel. A tÃ©cnica mostrou-se poderosa para ensinar um padrÃ£o especÃ­fico de resposta, tornando-a ideal para automatizar tarefas que envolvem anÃ¡lise e relatÃ³rio. No entanto, Ã© crucial entender as limitaÃ§Ãµes dos LLMs e aplicar a tÃ©cnica em contextos onde seu uso Ã© mais apropriado, como na geraÃ§Ã£o e formataÃ§Ã£o de texto seguindo uma lÃ³gica definida.

</aside>

---

### Least-to-Most Prompting: Dividindo Problemas Complexos

### Lembretes

- Least-to-Most Prompting
- DecomposiÃ§Ã£o de Problemas
- RaciocÃ­nio (Reasoning)
- Custo Computacional (Tokens)
- Acuracia

### AnotaÃ§Ãµes

**O Problema:**

- Modelos de linguagem (especialmente os mais antigos) tinhamÂ **dificuldade em tarefas de raciocÃ­nio lÃ³gico**Â complexo quando a pergunta era feita de uma sÃ³ vez (Zero-Shot).

**A SoluÃ§Ã£o: Least-to-Most Prompting**

- **O que Ã©:**Â TÃ©cnica desenvolvida pela Google Research que consiste emÂ **decompor automaticamente**Â um problema complexo emÂ **subproblemas menores e sequenciais**.
- **Como Funciona (Programaticamente):**
    1. O modelo Ã© instruÃ­do aÂ **gerar os prÃ³prios subproblemas**Â necessÃ¡rios para resolver a questÃ£o principal.
    2. EleÂ **resolve cada subproblema**Â individualmente.
    3. Por fim, usa asÂ **respostas dos subproblemas**Â para chegar Ã  resposta final do problema original.
- **Exemplo (ToboÃ¡gua):**
    - **Problema Original:**Â "Quantas vezes Amy pode escorregar em 15 minutos?"
    - **Subproblema Gerado:**Â "Quanto tempo dura cada viagem (subir + descer)?"
    - **Resposta do Subproblema:**Â 4 + 1 = 5 minutos.
    - **Resposta Final:**Â 15 min / 5 min por viagem =Â **3 vezes**.

**Resultados e ImplicaÃ§Ãµes:**

- **EficÃ¡cia:**Â Em modelos como o GPT-3, a tÃ©cnica elevou aÂ **acuracia em problemas de raciocÃ­nio de ~16% para ~99%**.
- **Custo:**Â A tÃ©cnica Ã©Â **mais custosa**Â (em termos de tokens usados na API), pois requer mÃºltiplas interaÃ§Ãµes ("idas e vindas") com o modelo para gerar e resolver cada subproblema.
- **Contexto:**Â Todo o histÃ³rico da conversa (subproblemas + respostas) Ã© enviado de volta ao modelo para manter o contexto, consumindo mais tokens.

**Conceito Central:**

- O nome "Least-to-Most" (Do Menor para o Maior) captura a essÃªncia da tÃ©cnica: comeÃ§ar com osÂ **componentes mais simples**Â (subproblemas) para, entÃ£o, construir a soluÃ§Ã£o para oÂ **problema maior**.

<aside>
ğŸ“Œ **RESUMO**:

OÂ **Least-to-Most Prompting**Â Ã© uma tÃ©cnica poderosa para superar as limitaÃ§Ãµes de raciocÃ­nio dos LLMs. Ela automatiza o princÃ­pio de "dividir tarefas complexas" instruindo o prÃ³prio modelo a quebrar um problema grande em subproblemas menores, resolvÃª-los e depois integrar as soluÃ§Ãµes. Embora extremamente eficaz para aumentar drasticamente a precisÃ£o em lÃ³gica e matemÃ¡tica, seu uso vem com umÂ **trade-off de custo**, jÃ¡ que consome significativamente mais tokens devido Ã  necessidade de mÃºltiplas interaÃ§Ãµes para gerar e resolver cada etapa. Ã‰ uma tÃ©cnica voltada principalmente para usoÂ **programÃ¡tico via API**Â em casos onde a precisÃ£o Ã© crÃ­tica.

</aside>

---

### Chain-of-Verification (CoVe): Verificando Fatos com o PrÃ³prio Modelo

### Lembretes

- Chain-of-Verification (CoVe)
- VerificaÃ§Ã£o de Fatos
- PrecisÃ£o Factual
- AlucinaÃ§Ã£o
- Custo Computacional

### AnotaÃ§Ãµes

**O Problema:**

- Modelos de linguagem podem gerarÂ **informaÃ§Ãµes incorretas**Â ou "alucinaÃ§Ãµes" (hallucinations), especialmente em questÃµes factuais (ex: datas, locais de nascimento, eventos histÃ³ricos).

**A SoluÃ§Ã£o: Chain-of-Verification (CoVe)**

- **O que Ã©:**Â Uma tÃ©cnica desenvolvida pela Meta que faz o modeloÂ **verificar suas prÃ³prias respostas**Â atravÃ©s de um processo estruturado de 4 etapas.
- **Objetivo:**Â Reduzir erros factuais e aumentar a confiabilidade das informaÃ§Ãµes geradas.

**As 4 Etapas do CoVe:**

1. **Resposta Inicial:**Â O modelo gera uma primeira resposta para o prompt (ex: "Cite polÃ­ticos nascidos em Nova Iorque" â†’ Hillary Clinton, Donald Trump, etc.).
2. **GeraÃ§Ã£o de Perguntas de VerificaÃ§Ã£o:**Â O modeloÂ **analisa sua prÃ³pria resposta inicial**Â e gera perguntas especÃ­ficas para verificar cada fato listado (ex: "Onde Hillary Clinton nasceu?", "Onde Donald Trump nasceu?").
3. **ExecuÃ§Ã£o das VerificaÃ§Ãµes:**Â O modeloÂ **responde a cada uma das perguntas de verificaÃ§Ã£o**Â que ele mesmo gerou, consultando seu conhecimento interno.
4. **Resposta Final Verificada:**Â O modeloÂ **compara as respostas de verificaÃ§Ã£o**Â com a resposta inicial,Â **corrige os erros**Â e produz uma resposta final mais precisa (ex: Remove Hillary Clinton da lista e adiciona outros polÃ­ticos que realmente nasceram em NY).

**Vantagens e Desvantagens:**

- **Vantagem:**Â Aumenta significativamente aÂ **precisÃ£o factual**Â das respostas, combatendo a alucinaÃ§Ã£o.
- **Desvantagem (Trade-off):**Â Assim como o Least-to-Most, Ã© uma tÃ©cnicaÂ **muito custosa**. Requer mÃºltiplas interaÃ§Ãµes (chamadas Ã  API), consumindo muitos tokens e tornando-aÂ **impraticÃ¡vel para uso manual**.
- **Uso PrÃ¡tico:**Â Ã‰ uma tÃ©cnica projetada para ser implementada de formaÂ **programÃ¡tica**, automatizando as 4 etapas via cÃ³digo e API.

<aside>
ğŸ“Œ **RESUMO**:

OÂ **Chain-of-Verification (CoVe)**Â Ã© uma tÃ©cnica sofisticada que transforma o modelo em seu prÃ³prioÂ **verificador de fatos**. AtravÃ©s de um processo de 4 etapas, ele Ã© forÃ§ado a questionar e validar suas respostas iniciais, levando a um resultado final muito mais confiÃ¡vel. Sua principal forÃ§a Ã©Â **reduzir drasticamente erros factuais**. No entanto, esse ganho em precisÃ£o vem com um altoÂ **custo computacional**Â (token), tornando-a uma ferramenta voltada para aplicaÃ§ÃµesÂ **automatizadas e programÃ¡ticas**Â onde a exatidÃ£o das informaÃ§Ãµes Ã© crÃ­tica, e nÃ£o para o uso casual em um chat.

</aside>

---

### Self-Consistency: Melhorando a PrecisÃ£o com RepetiÃ§Ã£o e Consenso

### Lembretes

- Self-Consistency (AutoconsistÃªncia)
- Chain of Thought (CoT)
- Consenso
- PrecisÃ£o EstatÃ­stica
- AutomaÃ§Ã£o (API)

### AnotaÃ§Ãµes

**O PrincÃ­pio:**

- **HipÃ³tese Central:**Â Se um modelo de linguagem Ã© questionadoÂ **vÃ¡rias vezes**Â sobre o mesmo problema, aÂ **resposta mais frequente**Â (o consenso) tem umaÂ **alta probabilidade de ser a correta**.
- **Base LÃ³gica:**Â Assume-se que o modelo acerta na maioria das vezes, e os erros sÃ£o aleatÃ³rios e nÃ£o consistentes.

**Como Funciona na PrÃ¡tica:**

1. **RepetiÃ§Ã£o:**Â O mesmo prompt (usando Chain of Thought) Ã© enviado para o modeloÂ **mÃºltiplas vezes**Â (ex: 4, 10 ou 15 vezes).
2. **Coleta de Respostas:**Â Todas as respostas geradas sÃ£o coletadas em uma lista.
3. **AnÃ¡lise de Consenso:**Â Identifica-se qual respostaÂ **aparece com mais frequÃªncia**Â (moda estatÃ­stica).
4. **Resposta Final:**Â A resposta de consenso Ã© considerada aÂ **resposta final e mais confiÃ¡vel**.

**ImplementaÃ§Ã£o TÃ©cnica (CÃ³digo):**

- A tÃ©cnica Ã© implementada de formaÂ **programÃ¡tica**, usando um loop (**`for`**) para fazer mÃºltiplas chamadas Ã Â **API**Â do modelo (ex: OpenAI).
- O cÃ³digo extrai a parte numÃ©rica da resposta de cada iteraÃ§Ã£o (ex: o valor apÃ³sÂ **`Resultado:`**Â ).
- Um parÃ¢metroÂ **`temperature`**Â > 0 (ex: 1) Ã© usado para garantirÂ **variaÃ§Ã£o**Â nas respostas entre cada loop.
- No final, o cÃ³digo calcula estatisticamente a resposta mais comum.

**Vantagens e ConsideraÃ§Ãµes:**

- **Vantagem:**Â Aumenta significativamente aÂ **confiabilidade**Â da resposta para problemas objetivos (ex: matemÃ¡tica, fatos).
- **Custo:**Â Ã‰ uma tÃ©cnicaÂ **custosa**Â (em tokens e tempo), pois requer mÃºltiplas chamadas Ã  API.
- **Aplicabilidade:**Â Ideal para ser usada de formaÂ **automÃ¡tica em sistemas**Â onde a precisÃ£o Ã© crÃ­tica, e nÃ£o manualmente.
- **LimitaÃ§Ã£o:**Â O cÃ³digo de exemplo precisa ser robusto para lidar com formatos de resposta inesperados do modelo.

<aside>
ğŸ“Œ **RESUMO**:

AÂ **Self-Consistency**Â Ã© uma tÃ©cnica simples porÃ©m poderosa que aproveita o poder estatÃ­stico doÂ **consenso**. Ao solicitar que o modelo resolva o mesmo problema diversas vezes e escolher a resposta mais frequente, a tÃ©cnica mitiga erros aleatÃ³rios e produz um resultado final muito mais confiÃ¡vel. Ela Ã© a evoluÃ§Ã£o natural do Chain of Thought, adicionando uma camada de verificaÃ§Ã£o estatÃ­stica. Por ser computacionalmente intensiva e custosa, seu uso Ã© mais indicado emÂ **aplicaÃ§Ãµes automatizadas via API**Â para tarefas onde a exatidÃ£o Ã© nÃ£o-negotiable, tornando-a uma ferramenta valiosa para desenvolvedores que integram LLMs em sistemas crÃ­ticos.

</aside>

---

### Aplicando tÃ©cnicas de Prompt no cotidiano

### Lembretes

- Prompts

### AnotaÃ§Ãµes

---

### **1. Prompt para Organizar Rotina de Estudos na Alura (Chain of Thought + Few-Shot)**

**TÃ©cnicas Usadas:**Â Chain of Thought (para explicar o raciocÃ­nio) + Few-Shot (com exemplos de estilo).

**Prompt:**

```
Atue como um consultor especializado em planejamento de estudos e produtividade. Sua tarefa Ã© me ajudar a criar uma rotina semanal de estudos para meus cursos na Alura.

Siga estes passos para construir minha rotina:

1.  **Coletar InformaÃ§Ãµes:** FaÃ§a perguntas para entender:
    *   Minhas **Ã¡reas de interesse** (ex: Front-end, Data Science, UX).
    *   Meu **objetivo** (ex: aprender do zero, aprofundar conhecimento, preparar-se para entrevista).
    *   Minha **disponibilidade semanal** (quantas horas por dia e quais dias posso estudar).
    *   **Outras atividades** fixas que tenho (trabalho, academia, compromissos).
    *   Meu **estilo de aprendizado preferido** (ex: prefiro mais prÃ¡tica do que teoria, gosto de intercalar com exercÃ­cios).

2.  **Propor uma Estrutura:** Com base nas minhas respostas, crie uma rotina semanal detalhada que intercale diferentes modos de estudo, por exemplo:
    *   **Assistir a videoaulas** (conteÃºdo novo)
    *   **PrÃ¡tica em projetos** (colocar a mÃ£o na massa)
    *   **ResoluÃ§Ã£o de exercÃ­cios** (fixar o conteÃºdo)
    *   **RevisÃ£o** (rever anotaÃ§Ãµes ou flashcards)

3.  **Fornecer a Rotina:** Apresente a rotina em formato de tabela, com os dias da semana, o tipo de atividade e o tema/tÃ³pico a ser estudado. Seja especÃ­fico e realista com o tempo.

Vamos comeÃ§ar? Por favor, comece me fazendo as perguntas do Passo 1.
```

---

### **2. Prompt para Simular uma Entrevista TÃ©cnica (Persona + Few-Shot)**

**TÃ©cnicas Usadas:**Â Persona (definir um papel) + Few-Shot (com exemplo de pergunta/resposta).

**Prompt:**

```
VocÃª serÃ¡ um entrevistador tÃ©cnico sÃªnior para a vaga de [INSIRA A VAGA AQUI, ex: Desenvolvedor(a) Front-end React]. Sua persona Ã© sÃ©ria, profissional, mas justa. VocÃª deve conduzir uma entrevista simulada comigo.

**InstruÃ§Ãµes:**
1.  **Estruture a entrevista em fases:** Comece com perguntas conceituais, depois parta para perguntas tÃ©cnicas especÃ­ficas e, por fim, proponha um desafio prÃ¡tico (um pequeno problema de cÃ³digo ou lÃ³gica).
2.  **FaÃ§a uma pergunta de cada vez.** Espere pela minha resposta antes de prosseguir.
3.  **ApÃ³s cada uma das minhas respostas,** forneÃ§a feedback imediato: diga o que estava correto, aponte erros ou omissÃµes e, se necessÃ¡rio, forneÃ§a a resposta ideal.
4.  **Use os seguintes tÃ³picos tÃ©cnicos como guia:** [LISTE TÃ“PICOS ESPECÃFICOS, ex: React Hooks (useState, useEffect), ComponentizaÃ§Ã£o, CSS-in-JS, Gerenciamento de Estado Global, Ciclo de Vida de um Componente].

**Exemplo de como vocÃª deve agir:**
*   **VocÃª (Entrevistador):** "Explique, em suas palavras, o que Ã© o Virtual DOM no React e que vantagem ele oferece."
*   **Eu (Candidato):** [Minha resposta]
*   **VocÃª (Entrevistador):** "Sua resposta cobriu o bÃ¡sico. VocÃª acertou ao mencionar a performance, mas esqueceu de citar que o Virtual DOM permite uma reconciliaÃ§Ã£o mais eficiente... A resposta mais completa seria: [forneÃ§a a resposta ideal]."

**Quando eu disser "Estou pronto(a)", comece a entrevista com a primeira pergunta.**
```

---

### **3. Prompt para Gerar um Quiz de RevisÃ£o (Few-Shot + Formato EspecÃ­fico)**

**TÃ©cnicas Usadas:**Â Few-Shot (com exemplo do formato) + InstruÃ§Ã£o clara para formataÃ§Ã£o.

**Prompt:**

```
VocÃª Ã© um assistente pedagÃ³gico. Com base no tÃ³pico de estudo que eu fornecer, sua tarefa Ã© criar um quiz de 5 perguntas e respostas para me ajudar na revisÃ£o e fixaÃ§Ã£o do conteÃºdo.

**Regras:**
*   As perguntas devem variar entre mÃºltipla escolha (com 4 opÃ§Ãµes) e verdadeiro/falso.
*   **O formato de saÃ­da deve ser exatamente o seguinte para cada pergunta:**
    ```
    Pergunta [NÃºmero]:
    [Texto da pergunta]
    a) [OpÃ§Ã£o A]
    b) [OpÃ§Ã£o B]
    c) [OpÃ§Ã£o C]
    d) [OpÃ§Ã£o D]
    (ou) Verdadeiro ( ) Falso ( ) // use apenas se for V/F

    Resposta: [Letra da resposta correta ou "Verdadeiro"/"Falso"]
    ExplicaÃ§Ã£o: [Uma explicaÃ§Ã£o concisa de por que essa Ã© a resposta correta]
    ---
    ```
*   **ApÃ³s gerar o quiz, espere eu responder.** SÃ³ entÃ£o vocÃª deve me dar o feedback, dizendo quantas eu acertei e revisando as que eu errei.

**Exemplo para o tÃ³pico "JavaScript - Array.map()":**

Pergunta 1:
Qual Ã© a finalidade principal do mÃ©todo `.map()` em JavaScript?
a) Iterar sobre um array para filtrar elementos especÃ­ficos.
b) Modificar o array original, adicionando um novo elemento.
c) Criar um novo array com os resultados da aplicaÃ§Ã£o de uma funÃ§Ã£o a cada elemento.
d) Ordenar os elementos de um array em ordem alfabÃ©tica.

Resposta: c
ExplicaÃ§Ã£o: O mÃ©todo `.map()` nÃ£o modifica o array original; ele cria um novo array populado com os resultados de uma funÃ§Ã£o chamada para cada elemento do array original.
---
**Agora, vamos comeÃ§ar. O tÃ³pico Ã©: [INSIRA SEU TÃ“PICO DE ESTUDO AQUI, ex: "Propriedades CSS Flexbox"]**
```

**Dica para Refinar:**Â Teste os prompts, veja as respostas e ajuste as instruÃ§Ãµes para ficarem ainda mais claras. Por exemplo, se o quiz gerar perguntas muito fÃ¡ceis, adicione ao prompt: "Crie perguntas desafiadoras que vÃ£o alÃ©m da memorizaÃ§Ã£o, testando a aplicaÃ§Ã£o prÃ¡tica do conceito."

Bons estudos e boa prÃ¡tica

---

### Engenharia de Prompt - Recap

### Lembretes

- Modelos de Linguagem (LLMs)
- Engenharia de Prompt
- Chain of Thought (CoT)
- Few-Shot / Zero-Shot
- Tokens & Temperatura

### AnotaÃ§Ãµes

**Fundamentos dos Modelos de Linguagem**

- **Funcionamento:**Â LLMs preveem a prÃ³xima palavra (token) com base em probabilidades aprendidas de um vasto conjunto de dados.
- **Word Embeddings:**Â Palavras sÃ£o representadas como vetores numÃ©ricos que capturam relaÃ§Ãµes de significado e proximidade semÃ¢ntica.
- **Temperatura:**Â ParÃ¢metro que controla a aleatoriedade das previsÃµes. Baixa = previsÃ­vel; Alta = criativa (mas possivelmente incoerente).
- **Tokens:**Â Unidades de processamento (podem ser palavras completas ou pedaÃ§os de palavras). O custo de uso de APIs Ã© calculado por token.

**PrincÃ­pios para um Prompt Ideal**

- **Clareza e Especificidade:**Â Seja extremamente claro, como se estivesse instruindo um estagiÃ¡rio. Defina formato, tom, pÃºblico-alvo e objetivo.
- **Dividir Tarefas Complexas:**Â Quebre problemas grandes em sub-tarefas menores e mais gerenciÃ¡veis para guiar o raciocÃ­nio do modelo.

**TÃ©cnicas Principais de Prompting**

- **Zero-Shot Prompting:**Â Fazer uma pergunta diretamente, sem exemplos. Ideal para tarefas simples.
- **Few-Shot Prompting:**Â Fornecer exemplos no prompt para "ensinar" o modelo o formato e estilo desejado da resposta.
- **Chain of Thought (CoT):**Â A tÃ©cnica mais poderosa. Incluir no prompt exemplos que mostrem oÂ **raciocÃ­nio passo a passo**Â para chegar Ã  resposta, nÃ£o apenas a resposta final. Isso aumenta a precisÃ£o em tarefas complexas.

**TÃ©cnicas AvanÃ§adas (Geralmente ProgramÃ¡ticas)**

- **Least-to-Most Prompting:**Â Instruir o modelo a decompor automaticamente um problema complexo em subproblemas, resolvÃª-los e depois integrar as soluÃ§Ãµes.
- **Chain-of-Verification (CoVe):**Â Fazer o modelo verificarÂ **seus prÃ³prios fatos**Â gerando e respondendo perguntas sobre sua resposta inicial.
- **Self-Consistency:**Â Fazer aÂ **mesma pergunta complexa mÃºltiplas vezes**Â e escolher a resposta que mais se repete (consenso), aumentando a confiabilidade estatÃ­stica.

<aside>
ğŸ“Œ **RESUMO**:

Percorremos **conceitos fundamentais**Â de como os LLMs funcionam (previsÃ£o de tokens, embeddings, temperatura) atÃ© asÂ **tÃ©cnicas mais avanÃ§adas**Â de Engenharia de Prompt. O grande segredo para prompts eficazes Ã© aÂ **clareza e a estrutura**. A tÃ©cnica mais impactante aprendida foi oÂ **Chain of Thought (Few-Shot + CoT)**, que ensina o modelo a raciocinar explicitamente. TÃ©cnicas como Self-Consistency e CoVe oferecem ganhos adicionais de precisÃ£o para sistemas automatizados via API, mas com um trade-off de custo. Agora vocÃª estÃ¡ equipado para se comunicar de forma mais eficaz e obter melhores resultados dos modelos de linguagem, seja no dia a dia ou em aplicaÃ§Ãµes profissionais.

</aside>

---